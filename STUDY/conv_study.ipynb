{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> conv提特征 向量点积往大收敛 提取的特证逐渐与原图相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.2349, -0.2782, -0.3082],\n",
      "          [ 0.2837,  0.2558,  0.1220],\n",
      "          [ 0.0704,  0.2870, -0.1825]]]], requires_grad=True)\n",
      "torch.Size([9, 3, 3, 3])\n",
      "tensor([[[[-0.8537, -0.2350],\n",
      "          [ 0.6817, -1.1483]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8677, -0.4955],\n",
      "          [-0.0107,  0.7152]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# demo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "kernel_size = 3 #传入元组 卷积核可以为矩形\n",
    "batch_size = 2\n",
    "bias = False\n",
    "input_size = [batch_size, in_channels, 4, 4]\n",
    "# 实例化类 首字母大写\n",
    "conv_layer_test = torch.nn.Conv2d(3, 9, kernel_size, bias=bias)\n",
    "# padding = sample\n",
    "conv_layer = torch.nn.Conv2d(1, 1, kernel_size, bias=bias)\n",
    "print(conv_layer.weight)\n",
    "x = torch.randn(input_size)\n",
    "x = F.dropout(x)\n",
    "x = conv_layer(x)\n",
    "print(conv_layer_test.weight.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Tensor' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m     25\u001b[0m kernel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_multiplication_for_conv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[0;32m     28\u001b[0m pytorch_api_output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)),kernel\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,kernel\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),kernel\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)))\n",
      "Cell \u001b[1;32mIn[140], line 21\u001b[0m, in \u001b[0;36mmatrix_multiplication_for_conv2d\u001b[1;34m(input, kernel, bias, stride, padding)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, output_w, stride):\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# 方法1\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m# p1d = (i, input_w -kernel_w-i,stride*i, input_h -kernel_h-stride*i)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# output[int(i/stride), int(j/stride)] = torch.sum(torch.mul(kernel_pad, input))、\u001b[39;00m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# 方法2\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         region \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[i:i\u001b[38;5;241m+\u001b[39mkernel_h,j:j\u001b[38;5;241m+\u001b[39mkernel_w]\n\u001b[1;32m---> 21\u001b[0m         output[\u001b[38;5;28mint\u001b[39m(i\u001b[38;5;241m/\u001b[39mstride), \u001b[38;5;28mint\u001b[39m(j\u001b[38;5;241m/\u001b[39mstride)] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Tensor' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# 用原始的矩阵运算实现二维卷积,先不考虑batchsize维度和channel维数\n",
    "def matrix_multiplication_for_conv2d(input, kernel, bias=None, stride=1, padding=0):\n",
    "    if padding > 0:\n",
    "        input = F.pad(input, (padding, padding, padding, padding))\n",
    "    input_h, input_w = input.shape\n",
    "    kernel_h, kernel_w = kernel.shape\n",
    "    print(input.size(0))\n",
    "    output_w = int(((input_w - kernel_w)/stride + 1))\n",
    "    output_h = int(((input_h - kernel_h)/stride + 1))\n",
    "    print(output_w)\n",
    "    output = torch.zeros(output_w, output_h)\n",
    "    for i in range(0, output_h, stride):\n",
    "        for j in range(0, output_w, stride):\n",
    "            # 方法1\n",
    "            # p1d = (i, input_w -kernel_w-i,stride*i, input_h -kernel_h-stride*i)\n",
    "            # kernel_pad = F.pad(kernel, p1d, 'constant', 0)\n",
    "            # # print(kernel_pad)\n",
    "            # output[int(i/stride), int(j/stride)] = torch.sum(torch.mul(kernel_pad, input))、\n",
    "            # 方法2\n",
    "            region = input[i:i+kernel_h,j:j+kernel_w]\n",
    "            output[int(i/stride), int(j/stride)] = torch.sum(region * kernel) + bias\n",
    "    return output\n",
    "# bias = torch.randn(1)\n",
    "x = torch.randn(6, 6)\n",
    "kernel = torch.randn(3, 3)\n",
    "output = matrix_multiplication_for_conv2d(x, kernel)\n",
    "print(output)\n",
    "pytorch_api_output = F.conv2d(x.reshape(1,1,x.size(0),x.size(1)),kernel.reshape(1,1,kernel.size(0),kernel.size(1)))\n",
    "print(pytorch_api_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
