{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> conv提特征 向量点积往大收敛 提取的特证逐渐与原图相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.3081,  0.1996,  0.1196],\n",
      "          [-0.2311, -0.0334,  0.2912],\n",
      "          [ 0.1883,  0.1224,  0.1053]]]], requires_grad=True)\n",
      "torch.Size([9, 3, 3, 3])\n",
      "tensor([[[[-0.6239, -1.4214],\n",
      "          [ 1.0948, -0.4845]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1987, -0.5851],\n",
      "          [ 1.0835, -1.0004]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "# demo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "kernel_size = 3 #传入元组 卷积核可以为矩形\n",
    "batch_size = 2\n",
    "bias = False\n",
    "input_size = [batch_size, in_channels, 4, 4]\n",
    "# 实例化类 首字母大写\n",
    "conv_layer_test = torch.nn.Conv2d(3, 9, kernel_size, bias=bias)\n",
    "# padding = sample\n",
    "conv_layer = torch.nn.Conv2d(1, 1, kernel_size, bias=bias)\n",
    "print(conv_layer.weight)\n",
    "x = torch.randn(input_size)\n",
    "x = F.dropout(x)\n",
    "x = conv_layer(x)\n",
    "print(conv_layer_test.weight.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "tensor([[-3.6580, -0.9842,  3.4693,  1.8781],\n",
      "        [ 3.9370, -0.3824,  0.7045, -2.0984],\n",
      "        [-0.3617,  1.8660, -2.1826, -0.2953],\n",
      "        [-3.0925, -0.4673,  2.7907, -1.5380]])\n",
      "tensor([[[[-3.8849, -1.2110,  3.2424,  1.6512],\n",
      "          [ 3.7101, -0.6093,  0.4777, -2.3252],\n",
      "          [-0.5886,  1.6391, -2.4095, -0.5222],\n",
      "          [-3.3194, -0.6941,  2.5638, -1.7648]]]])\n"
     ]
    }
   ],
   "source": [
    "# 用原始的矩阵运算实现二维卷积,先不考虑batchsize维度和channel维数\n",
    "def matrix_multiplication_for_conv2d(input, kernel, bias=0, stride=1, padding=0):\n",
    "    if padding > 0:\n",
    "        input = F.pad(input, (padding, padding, padding, padding))\n",
    "    input_h, input_w = input.shape\n",
    "    kernel_h, kernel_w = kernel.shape\n",
    "    print(input.size(0))\n",
    "    output_w = int(((input_w - kernel_w)/stride + 1))\n",
    "    output_h = int(((input_h - kernel_h)/stride + 1))\n",
    "    print(output_w)\n",
    "    output = torch.zeros(output_w, output_h)\n",
    "    for i in range(0, output_h, stride):\n",
    "        for j in range(0, output_w, stride):\n",
    "            # 方法1\n",
    "            # p1d = (i, input_w -kernel_w-i,stride*i, input_h -kernel_h-stride*i)\n",
    "            # kernel_pad = F.pad(kernel, p1d, 'constant', 0)\n",
    "            # # print(kernel_pad)\n",
    "            # output[int(i/stride), int(j/stride)] = torch.sum(torch.mul(kernel_pad, input))、\n",
    "            # 方法2\n",
    "            region = input[i:i+kernel_h,j:j+kernel_w]\n",
    "            output[int(i/stride), int(j/stride)] = torch.sum(region * kernel)+bias\n",
    "    return output\n",
    "bias = torch.randn(1)\n",
    "x = torch.randn(6, 6)\n",
    "kernel = torch.randn(3, 3)\n",
    "output = matrix_multiplication_for_conv2d(x, kernel,bias=bias)\n",
    "print(output)\n",
    "pytorch_api_output = F.conv2d(x.reshape(1,1,x.size(0),x.size(1)),kernel.reshape(1,1,kernel.size(0),kernel.size(1)))\n",
    "print(pytorch_api_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> flatten 版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "tensor([[-0.5224,  0.0477,  2.1909,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[[[-0.5224, -0.0982, -1.9555, -0.1725],\n",
      "          [ 0.0477,  2.1909,  2.0212, -0.9861],\n",
      "          [-1.6592, -1.7292,  2.4450,  1.0094],\n",
      "          [ 0.2891,  0.1795, -1.9192,  0.3684]]]])\n"
     ]
    }
   ],
   "source": [
    "# 用原始的矩阵运算实现二维卷积,先不考虑batchsize维度和channel维数,flatten版本 flatten作用把张量拉直成1维\n",
    "def matrix_multiplication_for_conv2d_flatten(input, kernel, bias=0, stride=1, padding=0):\n",
    "    if padding > 0:\n",
    "        input = F.pad(input, (padding, padding, padding, padding))\n",
    "    input_h, input_w = input.shape\n",
    "    kernel_h, kernel_w = kernel.shape\n",
    "    print(input.size(0))\n",
    "    output_w = int(((input_w - kernel_w)/stride + 1))\n",
    "    output_h = int(((input_h - kernel_h)/stride + 1))\n",
    "    print(output_w)\n",
    "    output = torch.zeros(output_w, output_h)\n",
    "    region_matrix = torch.zeros(output.numel(), kernel.numel())\n",
    "    kernel_matrix = kernel.reshape((kernel.numel(), 1))\n",
    "    \n",
    "    for i in range(0, output_h-kernel_h+1, stride):\n",
    "        for j in range(0, output_w-kernel_w+1, stride):\n",
    "            region = input[i:i+kernel_h, j:j+kernel_w] \n",
    "            region_vector = torch.flatten(region)\n",
    "            region_matrix[i+j] = region_vector\n",
    "    output_matrix = region_matrix @ kernel_matrix\n",
    "    output = output_matrix.reshape((output_h, output_w))\n",
    "    return output\n",
    "bias = torch.randn(1)\n",
    "x = torch.randn(6, 6)\n",
    "kernel = torch.randn(3, 3)\n",
    "output = matrix_multiplication_for_conv2d_flatten(x, kernel,bias=bias)\n",
    "print(output)\n",
    "pytorch_api_output = F.conv2d(x.reshape(1,1,x.size(0),x.size(1)),kernel.reshape(1,1,kernel.size(0),kernel.size(1)))\n",
    "print(pytorch_api_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESRGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
