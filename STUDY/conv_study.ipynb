{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> conv提特征 向量点积往大收敛 提取的特证逐渐与原图相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.2349, -0.2782, -0.3082],\n",
      "          [ 0.2837,  0.2558,  0.1220],\n",
      "          [ 0.0704,  0.2870, -0.1825]]]], requires_grad=True)\n",
      "torch.Size([9, 3, 3, 3])\n",
      "tensor([[[[-0.8537, -0.2350],\n",
      "          [ 0.6817, -1.1483]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8677, -0.4955],\n",
      "          [-0.0107,  0.7152]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "outputs": [],
   "source": [
    "# demo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "kernel_size = 3 #传入元组 卷积核可以为矩形\n",
    "batch_size = 2\n",
    "bias = False\n",
    "input_size = [batch_size, in_channels, 4, 4]\n",
    "# 实例化类 首字母大写\n",
    "conv_layer_test = torch.nn.Conv2d(3, 9, kernel_size, bias=bias)\n",
    "# padding = sample\n",
    "conv_layer = torch.nn.Conv2d(1, 1, kernel_size, bias=bias)\n",
    "print(conv_layer.weight)\n",
    "x = torch.randn(input_size)\n",
    "x = F.dropout(x)\n",
    "x = conv_layer(x)\n",
    "print(conv_layer_test.weight.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用原始的矩阵运算实现二维卷积,先不考虑batchsize维度和channel维数\n",
    "def matrix_multiplication_for_conv2d(input, kernel, bias=0, stride=1, padding=0):\n",
    "    if padding > 0:\n",
    "        input = F.pad(input, (padding, padding, padding, padding))\n",
    "    input_h, input_w = input.shape\n",
    "    kernel_h, kernel_w = kernel.shape\n",
    "    print(input.size(0))\n",
    "    output_w = int(((input_w - kernel_w)/stride + 1))\n",
    "    output_h = int(((input_h - kernel_h)/stride + 1))\n",
    "    print(output_w)\n",
    "    output = torch.zeros(output_w, output_h)\n",
    "    for i in range(0, output_h, stride):\n",
    "        for j in range(0, output_w, stride):\n",
    "            # 方法1\n",
    "            # p1d = (i, input_w -kernel_w-i,stride*i, input_h -kernel_h-stride*i)\n",
    "            # kernel_pad = F.pad(kernel, p1d, 'constant', 0)\n",
    "            # # print(kernel_pad)\n",
    "            # output[int(i/stride), int(j/stride)] = torch.sum(torch.mul(kernel_pad, input))、\n",
    "            # 方法2\n",
    "            region = input[i:i+kernel_h,j:j+kernel_w]\n",
    "            output[int(i/stride), int(j/stride)] = torch.sum(region * kernel)+bias\n",
    "    return output\n",
    "bias = torch.randn(1)\n",
    "x = torch.randn(6, 6)\n",
    "kernel = torch.randn(3, 3)\n",
    "output = matrix_multiplication_for_conv2d(x, kernel,bias=bias)\n",
    "print(output)\n",
    "pytorch_api_output = F.conv2d(x.reshape(1,1,x.size(0),x.size(1)),kernel.reshape(1,1,kernel.size(0),kernel.size(1)))\n",
    "print(pytorch_api_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> flatten 版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用原始的矩阵运算实现二维卷积,先不考虑batchsize维度和channel维数,flatten版本 flatten作用把张量拉直成1维\n",
    "def matrix_multiplication_for_conv2d_flatten(input, kernel, bias=0, stride=1, padding=0):\n",
    "    F,fl\n",
    "    if padding > 0:\n",
    "        input = F.pad(input, (padding, padding, padding, padding))\n",
    "    input_h, input_w = input.shape\n",
    "    kernel_h, kernel_w = kernel.shape\n",
    "    print(input.size(0))\n",
    "    output_w = int(((input_w - kernel_w)/stride + 1))\n",
    "    output_h = int(((input_h - kernel_h)/stride + 1))\n",
    "    print(output_w)\n",
    "    output = torch.zeros(output_w, output_h)\n",
    "    for i in range(0, output_h, stride):\n",
    "        for j in range(0, output_w, stride):\n",
    "            region =    \n",
    "    return output\n",
    "bias = torch.randn(1)\n",
    "x = torch.randn(6, 6)\n",
    "kernel = torch.randn(3, 3)\n",
    "output = matrix_multiplication_for_conv2d_flatten(x, kernel,bias=bias)\n",
    "print(output)\n",
    "pytorch_api_output = F.conv2d(x.reshape(1,1,x.size(0),x.size(1)),kernel.reshape(1,1,kernel.size(0),kernel.size(1)))\n",
    "print(pytorch_api_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
