{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# print(\"当前设备名称：\", torch.cuda.get_device_name(device) if device.type == 'cuda' else 'CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1、生成词索引构成的序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 1, 0, 0, 0],\n",
      "        [5, 5, 7, 7, 0]])\n",
      "tensor([[3, 2, 7, 4, 0],\n",
      "        [6, 7, 7, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "model_dim = 8\n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "max_position_len = 5\n",
    "# src_len = torch.randint(2,5,(batch_size,))\n",
    "# tgt_len = torch.randint(2,5,(batch_size,))\n",
    "src_len = torch.Tensor([2, 4]).to(torch.int32)\n",
    "tgt_len = torch.Tensor([4, 3]).to(torch.int32)\n",
    "# 词索引构成的序列\n",
    "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_src_words, (L,)), (0, max_src_seq_len-L)), 0) \\\n",
    "                     for L in src_len])\n",
    "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_tgt_words, (L,)), (0, max_tgt_seq_len-L)), 0) \\\n",
    "                     for L in tgt_len])\n",
    "print(src_seq)\n",
    "print(tgt_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2、采用Embedding的forward方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5355, -0.9739, -0.4599,  0.2081, -0.6606, -0.4836,  0.1033,\n",
      "           0.9948],\n",
      "         [-0.2193,  0.3768, -1.1767,  0.7611, -1.0107,  0.0720,  0.1343,\n",
      "           0.0700],\n",
      "         [ 0.3928, -0.1414, -0.7111, -1.4414, -0.6621,  1.3227, -0.2484,\n",
      "          -0.3267],\n",
      "         [ 0.3928, -0.1414, -0.7111, -1.4414, -0.6621,  1.3227, -0.2484,\n",
      "          -0.3267],\n",
      "         [ 0.3928, -0.1414, -0.7111, -1.4414, -0.6621,  1.3227, -0.2484,\n",
      "          -0.3267]],\n",
      "\n",
      "        [[ 1.7584, -1.2378, -0.6316,  0.6291,  0.5500, -2.1515, -2.3653,\n",
      "           0.3652],\n",
      "         [ 1.7584, -1.2378, -0.6316,  0.6291,  0.5500, -2.1515, -2.3653,\n",
      "           0.3652],\n",
      "         [ 2.1432, -0.0489,  0.1226,  0.3359, -0.6791,  2.3552,  0.4729,\n",
      "           0.1686],\n",
      "         [ 2.1432, -0.0489,  0.1226,  0.3359, -0.6791,  2.3552,  0.4729,\n",
      "           0.1686],\n",
      "         [ 0.3928, -0.1414, -0.7111, -1.4414, -0.6621,  1.3227, -0.2484,\n",
      "          -0.3267]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 实例化embedding # requires_grad \n",
    "# weight是随机的，训练时更新\n",
    "src_embedding_table = nn.Embedding(max_num_src_words+1, model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1, model_dim)\n",
    "# print(src_embedding_table.weight, tgt_embedding_table.weight)\n",
    "# Embedding存在 --call-- forward方法隐式\n",
    "src_embedding = src_embedding_table(src_seq)\n",
    "tgt_embedding_table = tgt_embedding_table(tgt_seq)\n",
    "print(src_embedding)\n",
    "# 由于为0 底下3排一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3、生成pos—embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np Time (microseconds): 2277.1358489990234\n",
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  9.5042e-01,  9.9833e-02,  9.9950e-01,  9.9998e-03,\n",
      "          9.9999e-01,  1.0000e-03,  1.0000e+00],\n",
      "        [ 9.0930e-01,  8.0658e-01,  1.9867e-01,  9.9800e-01,  1.9999e-02,\n",
      "          9.9998e-01,  2.0000e-03,  1.0000e+00],\n",
      "        [ 1.4112e-01,  5.8275e-01,  2.9552e-01,  9.9550e-01,  2.9995e-02,\n",
      "          9.9995e-01,  3.0000e-03,  1.0000e+00],\n",
      "        [-7.5680e-01,  3.0114e-01,  3.8942e-01,  9.9201e-01,  3.9989e-02,\n",
      "          9.9992e-01,  4.0000e-03,  1.0000e+00]])\n",
      "torch Time (microseconds): 1752.8533935546875\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# pos embedding    method1 \n",
    "start_time = time.time()\n",
    "pos_embedding = torch.zeros(max_position_len, model_dim)\n",
    "for i in range(0, model_dim):\n",
    "    for j in range(0, max_position_len):\n",
    "        if i%2 == 0:\n",
    "            # print(i,j)\n",
    "            pos_embedding[j, i] = np.sin(j/np.power(10000, (i/model_dim)))\n",
    "        else:\n",
    "            pos_embedding[j, i] = np.cos(j/np.power(10000, (i/model_dim)))\n",
    "# print(pos_embedding)\n",
    "end_time = time.time()\n",
    "# 计算执行时间并转换为微秒\n",
    "execution_time_microseconds = (end_time - start_time) * 1e6\n",
    "# 打印执行时间\n",
    "print(\"np Time (microseconds):\", execution_time_microseconds)\n",
    "#///////////////////////////////////////////////////////////////////////////////////////////\n",
    "# pos embedding    method2 \n",
    "start_time = time.time()\n",
    "pos_mat = torch.arange(max_position_len).reshape(-1, 1) \n",
    "i_mat = torch.pow(10000, torch.arange(0, 8, 2).reshape((1, -1))/model_dim)\n",
    "i1_mat = torch.pow(10000, torch.arange(1, 8, 2).reshape((1, -1))/model_dim)\n",
    "# print(pos_mat, i_mat, i1_mat)\n",
    "pe_embedding_table = torch.zeros(max_position_len, model_dim)\n",
    "pe_embedding_table[:, 0::2] = torch.sin(pos_mat/i_mat)\n",
    "pe_embedding_table[:, 1::2] = torch.cos(pos_mat/i1_mat)\n",
    "print(pe_embedding_table)\n",
    "end_time = time.time()\n",
    "# 计算执行时间并转换为微秒\n",
    "execution_time_microseconds = (end_time - start_time) * 1e6\n",
    "# 打印执行时间\n",
    "print(\"torch Time (microseconds):\", execution_time_microseconds)\n",
    "#///////////////////////////////////////////////////////////////////////////////////////////\n",
    "# print(torch.sub(pos_embedding, pe_embedding_table))\n",
    "pe_embedding = nn.Embedding(max_position_len, model_dim)\n",
    "# 位置编码训练中不发生变化requires_grad=False\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad=False)\n",
    "# 注意 这里给embedding的是位置 不是词的编号\n",
    "# src_p=torch.zeros_like(src_seq)\n",
    "# for i in range(src_p.size(0)):\n",
    "#     for j in range(src_p.size(1)):\n",
    "#         src_p[i][j] = j \n",
    "# print(src_p)\n",
    "# src_pe_embedding =pe_embedding(src_p)\n",
    "src_pe_embedding =pe_embedding(torch.cat([pos_mat,pos_mat], 1).transpose(-1,-2))\n",
    "print(torch.cat([pos_mat,pos_mat], 1).transpose(-1,-2))\n",
    "# print(src_pe_embedding)\n",
    "tgt_pe_embedding = src_pe_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 4、生成enc_self_attn_mask 无因果关系   对词向量相似度进行masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 1]) \n",
      " tensor([[[1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]])\n",
      "tensor([[[False, False,  True,  True],\n",
      "         [False, False,  True,  True],\n",
      "         [ True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False],\n",
      "         [False, False, False, False],\n",
      "         [False, False, False, False],\n",
      "         [False, False, False, False]]])\n",
      "tensor([[[0.0146, 0.9854, 0.0000, 0.0000],\n",
      "         [0.4324, 0.5676, 0.0000, 0.0000],\n",
      "         [   nan,    nan,    nan,    nan],\n",
      "         [   nan,    nan,    nan,    nan]],\n",
      "\n",
      "        [[0.4723, 0.0236, 0.2912, 0.2130],\n",
      "         [0.7549, 0.0775, 0.0501, 0.1174],\n",
      "         [0.1201, 0.0977, 0.3192, 0.4629],\n",
      "         [0.2615, 0.2745, 0.3395, 0.1246]]])\n"
     ]
    }
   ],
   "source": [
    "# 这里不是三角矩阵# 这里不是三角矩阵 没有因果关系 多用矩阵相乘 转置 升维\n",
    "vaild_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(src_len)-L)),0) for L in src_len]), 2)\n",
    "# print(vaild_encoder_pos.shape, \"\\n\", vaild_encoder_pos)\n",
    "# vaild_encoder_pos = torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(src_len)-L)),0) for L in src_len])\n",
    "print(vaild_encoder_pos.shape, \"\\n\", vaild_encoder_pos)\n",
    "# 这里不是三角矩阵\n",
    "# print(torch.tril(torch.ones(4, 4)))\n",
    "# vaild_mask = vaild_encoder_pos.transpose(1,2)*torch.ones(4, 4)*vaild_encoder_pos\n",
    "# print(vaild_mask.shape, \"\\n\", vaild_mask)\n",
    "# print(torch.bmm(torch.unsqueeze(torch.ones(4, 4),0), torch.unsqueeze(torch.ones(4, 4),0)))\n",
    "# print(torch.ones(4, 4)*torch.ones(4, 4))\n",
    "valid_encoder_pos_matrix = torch.bmm(vaild_encoder_pos, vaild_encoder_pos.transpose(1, 2))\n",
    "invalid_encoder_pos_matrix = 1-valid_encoder_pos_matrix\n",
    "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)\n",
    "print(mask_encoder_self_attention)\n",
    "#假设是vk注意力权重\n",
    "score = torch.randn(batch_size, max(src_len), max(src_len))\n",
    "masked_score = score.masked_fill(mask_encoder_self_attention, -np.inf)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5、get_attn_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 4]) \n",
      " torch.Size([2, 4, 1])\n",
      "tensor([[[1., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1.]]]) \n",
      " tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.]]])\n",
      "tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0.]]]) \n",
      " torch.Size([2, 4, 4])\n",
      "tensor([[[0.5509, 0.4491, 0.0000, 0.0000],\n",
      "         [0.5685, 0.4315, 0.0000, 0.0000],\n",
      "         [0.8273, 0.1727, 0.0000, 0.0000],\n",
      "         [0.8970, 0.1030, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.6837, 0.1536, 0.0734, 0.0894],\n",
      "         [0.0444, 0.1442, 0.2353, 0.5760],\n",
      "         [0.2831, 0.0628, 0.6228, 0.0312],\n",
      "         [   nan,    nan,    nan,    nan]]])\n"
     ]
    }
   ],
   "source": [
    "enc_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(src_len)-L)),0) for L in src_len]), 1)\n",
    "dec_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(tgt_len)-L)),0) for L in tgt_len]), 2)\n",
    "print(enc_encoder_pos.shape, \"\\n\", dec_encoder_pos.shape)\n",
    "print(enc_encoder_pos, \"\\n\", dec_encoder_pos)\n",
    "# 具体维度通过【】的奇偶特征决定\n",
    "get_attn_pad_mask = torch.bmm(dec_encoder_pos, enc_encoder_pos, )\n",
    "print(get_attn_pad_mask, \"\\n\", get_attn_pad_mask.shape)\n",
    "score = torch.randn(2, max(src_len), max(tgt_len))\n",
    "masked_score = score.masked_fill((1-get_attn_pad_mask).to(torch.bool), -np.inf)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 6、dec_self_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 4])\n",
      "tensor([[[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "tensor([[[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "tril = torch.unsqueeze(torch.tril(torch.ones(max(tgt_len), max(tgt_len))), 0)\n",
    "print(tril.shape)\n",
    "# tril = tril.expand(2, 4, 4) \n",
    "tril = torch.cat((tril, tril ))\n",
    "print(tril)\n",
    "dec_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(tgt_len)-L)),0) for L in tgt_len]), 2)\n",
    "valid_decoder_pos_matrix = torch.bmm(dec_encoder_pos,dec_encoder_pos.transpose(1, 2))\n",
    "dec_self_attn_mask = valid_decoder_pos_matrix*tril\n",
    "print(dec_self_attn_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 7、loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8926, 2.9831, 2.7514],\n",
      "        [1.8626, 2.4915, 0.8839]])\n",
      "tensor([[0.8926, 2.9831, 2.7514],\n",
      "        [1.8626, 2.4915, 0.8839]])\n"
     ]
    }
   ],
   "source": [
    "logits = torch.randn(2,3,4)\n",
    "# batchsize=2 seqlen=3 vocal_size=4\n",
    "label = torch.randint(0, 4, (2,3))\n",
    "logits = logits.transpose(1,2)\n",
    "print(F.cross_entropy(logits, label,reduction = 'none'))\n",
    "print(F.cross_entropy(logits, label,ignore_index = 2, reduction = 'none'))\n",
    "# print(F.cross_entropy(logits, label,ignore_index = 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
