{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前设备名称： NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"当前设备名称：\", torch.cuda.get_device_name(device) if device.type == 'cuda' else 'CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1、生成词索引构成的序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 1, 0, 0, 0],\n",
      "        [3, 1, 7, 7, 0]])\n",
      "tensor([[2, 1, 7, 6, 0],\n",
      "        [7, 5, 6, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "model_dim = 8\n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "max_position_len = 5\n",
    "# src_len = torch.randint(2,5,(batch_size,))\n",
    "# tgt_len = torch.randint(2,5,(batch_size,))\n",
    "src_len = torch.Tensor([2, 4]).to(torch.int32)\n",
    "tgt_len = torch.Tensor([4, 3]).to(torch.int32)\n",
    "# 词索引构成的序列\n",
    "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_src_words, (L,)), (0, max_src_seq_len-L)), 0) \\\n",
    "                     for L in src_len])\n",
    "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_tgt_words, (L,)), (0, max_tgt_seq_len-L)), 0) \\\n",
    "                     for L in tgt_len])\n",
    "print(src_seq)\n",
    "print(tgt_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2、采用Embedding的forward方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2837, -0.4433,  0.6236,  0.1594,  1.9104, -0.5462,  1.0532,\n",
      "          -0.0240],\n",
      "         [-1.7059, -1.0046, -0.0326, -0.0299,  2.3425, -1.7953, -1.8357,\n",
      "           0.7659],\n",
      "         [-0.1718, -1.8654, -0.1987, -0.8014, -1.0334,  0.4024,  1.1313,\n",
      "           1.7135],\n",
      "         [-0.1718, -1.8654, -0.1987, -0.8014, -1.0334,  0.4024,  1.1313,\n",
      "           1.7135],\n",
      "         [-0.1718, -1.8654, -0.1987, -0.8014, -1.0334,  0.4024,  1.1313,\n",
      "           1.7135]],\n",
      "\n",
      "        [[-1.6621,  0.1629, -1.6330, -1.4075,  0.8662,  0.4910, -0.4970,\n",
      "          -0.8949],\n",
      "         [-1.7059, -1.0046, -0.0326, -0.0299,  2.3425, -1.7953, -1.8357,\n",
      "           0.7659],\n",
      "         [-0.3840, -0.3035,  0.7473, -0.4693,  0.8002, -0.2641, -1.3366,\n",
      "           1.0725],\n",
      "         [-0.3840, -0.3035,  0.7473, -0.4693,  0.8002, -0.2641, -1.3366,\n",
      "           1.0725],\n",
      "         [-0.1718, -1.8654, -0.1987, -0.8014, -1.0334,  0.4024,  1.1313,\n",
      "           1.7135]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 实例化embedding # requires_grad \n",
    "# weight是随机的，训练时更新\n",
    "src_embedding_table = nn.Embedding(max_num_src_words+1, model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1, model_dim)\n",
    "# print(src_embedding_table.weight, tgt_embedding_table.weight)\n",
    "# Embedding存在 --call-- forward方法隐式\n",
    "src_embedding = src_embedding_table(src_seq)\n",
    "tgt_embedding_table = tgt_embedding_table(tgt_seq)\n",
    "print(src_embedding)\n",
    "# 由于为0 底下3排一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3、生成pos—embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np Time (microseconds): 1001.1196136474609\n",
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  9.5042e-01,  9.9833e-02,  9.9950e-01,  9.9998e-03,\n",
      "          9.9999e-01,  1.0000e-03,  1.0000e+00],\n",
      "        [ 9.0930e-01,  8.0658e-01,  1.9867e-01,  9.9800e-01,  1.9999e-02,\n",
      "          9.9998e-01,  2.0000e-03,  1.0000e+00],\n",
      "        [ 1.4112e-01,  5.8275e-01,  2.9552e-01,  9.9550e-01,  2.9995e-02,\n",
      "          9.9995e-01,  3.0000e-03,  1.0000e+00],\n",
      "        [-7.5680e-01,  3.0114e-01,  3.8942e-01,  9.9201e-01,  3.9989e-02,\n",
      "          9.9992e-01,  4.0000e-03,  1.0000e+00]])\n",
      "torch Time (microseconds): 997.5433349609375\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n",
      "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  9.5042e-01,  9.9833e-02,  9.9950e-01,  9.9998e-03,\n",
      "           9.9999e-01,  1.0000e-03,  1.0000e+00],\n",
      "         [ 9.0930e-01,  8.0658e-01,  1.9867e-01,  9.9800e-01,  1.9999e-02,\n",
      "           9.9998e-01,  2.0000e-03,  1.0000e+00],\n",
      "         [ 1.4112e-01,  5.8275e-01,  2.9552e-01,  9.9550e-01,  2.9995e-02,\n",
      "           9.9995e-01,  3.0000e-03,  1.0000e+00],\n",
      "         [-7.5680e-01,  3.0114e-01,  3.8942e-01,  9.9201e-01,  3.9989e-02,\n",
      "           9.9992e-01,  4.0000e-03,  1.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  9.5042e-01,  9.9833e-02,  9.9950e-01,  9.9998e-03,\n",
      "           9.9999e-01,  1.0000e-03,  1.0000e+00],\n",
      "         [ 9.0930e-01,  8.0658e-01,  1.9867e-01,  9.9800e-01,  1.9999e-02,\n",
      "           9.9998e-01,  2.0000e-03,  1.0000e+00],\n",
      "         [ 1.4112e-01,  5.8275e-01,  2.9552e-01,  9.9550e-01,  2.9995e-02,\n",
      "           9.9995e-01,  3.0000e-03,  1.0000e+00],\n",
      "         [-7.5680e-01,  3.0114e-01,  3.8942e-01,  9.9201e-01,  3.9989e-02,\n",
      "           9.9992e-01,  4.0000e-03,  1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# pos embedding    method1 \n",
    "start_time = time.time()\n",
    "pos_embedding = torch.zeros(max_position_len, model_dim)\n",
    "for i in range(0, model_dim):\n",
    "    for j in range(0, max_position_len):\n",
    "        if i%2 == 0:\n",
    "            # print(i,j)\n",
    "            pos_embedding[j, i] = np.sin(j/np.power(10000, (i/model_dim)))\n",
    "        else:\n",
    "            pos_embedding[j, i] = np.cos(j/np.power(10000, (i/model_dim)))\n",
    "# print(pos_embedding)\n",
    "end_time = time.time()\n",
    "# 计算执行时间并转换为微秒\n",
    "execution_time_microseconds = (end_time - start_time) * 1e6\n",
    "# 打印执行时间\n",
    "print(\"np Time (microseconds):\", execution_time_microseconds)\n",
    "#///////////////////////////////////////////////////////////////////////////////////////////\n",
    "# pos embedding    method2 \n",
    "start_time = time.time()\n",
    "pos_mat = torch.arange(max_position_len).reshape(-1, 1) \n",
    "i_mat = torch.pow(10000, torch.arange(0, 8, 2).reshape((1, -1))/model_dim)\n",
    "i1_mat = torch.pow(10000, torch.arange(1, 8, 2).reshape((1, -1))/model_dim)\n",
    "# print(pos_mat, i_mat, i1_mat)\n",
    "pe_embedding_table = torch.zeros(max_position_len, model_dim)\n",
    "pe_embedding_table[:, 0::2] = torch.sin(pos_mat/i_mat)\n",
    "pe_embedding_table[:, 1::2] = torch.cos(pos_mat/i1_mat)\n",
    "print(pe_embedding_table)\n",
    "end_time = time.time()\n",
    "# 计算执行时间并转换为微秒\n",
    "execution_time_microseconds = (end_time - start_time) * 1e6\n",
    "# 打印执行时间\n",
    "print(\"torch Time (microseconds):\", execution_time_microseconds)\n",
    "#///////////////////////////////////////////////////////////////////////////////////////////\n",
    "# print(torch.sub(pos_embedding, pe_embedding_table))\n",
    "pe_embedding = nn.Embedding(max_position_len, model_dim)\n",
    "# 位置编码训练中不发生变化requires_grad=False\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad=False)\n",
    "# 注意 这里给embedding的是位置 不是词的编号\n",
    "# src_p=torch.zeros_like(src_seq)\n",
    "# for i in range(src_p.size(0)):\n",
    "#     for j in range(src_p.size(1)):\n",
    "#         src_p[i][j] = j \n",
    "# print(src_p)\n",
    "# src_pe_embedding =pe_embedding(src_p)\n",
    "src_pe_embedding =pe_embedding(torch.cat([pos_mat,pos_mat], 1).transpose(-1,-2))\n",
    "print(torch.cat([pos_mat,pos_mat], 1).transpose(-1,-2))\n",
    "print(src_pe_embedding)\n",
    "tgt_pe_embedding = src_pe_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 4、生成enc_self_attn_mask 无因果关系   对词向量相似度进行masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 1]) \n",
      " tensor([[[1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]])\n",
      "tensor([[[False, False,  True,  True],\n",
      "         [False, False,  True,  True],\n",
      "         [ True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False],\n",
      "         [False, False, False, False],\n",
      "         [False, False, False, False],\n",
      "         [False, False, False, False]]])\n",
      "tensor([[[0.4808, 0.5192, 0.0000, 0.0000],\n",
      "         [0.9586, 0.0414, 0.0000, 0.0000],\n",
      "         [   nan,    nan,    nan,    nan],\n",
      "         [   nan,    nan,    nan,    nan]],\n",
      "\n",
      "        [[0.0808, 0.1797, 0.6634, 0.0761],\n",
      "         [0.0682, 0.5986, 0.2450, 0.0882],\n",
      "         [0.0549, 0.0838, 0.1006, 0.7608],\n",
      "         [0.7652, 0.1342, 0.0709, 0.0297]]])\n"
     ]
    }
   ],
   "source": [
    "# 这里不是三角矩阵# 这里不是三角矩阵 没有因果关系 多用矩阵相乘 转置 升维\n",
    "vaild_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(src_len)-L)),0) for L in src_len]), 2)\n",
    "# print(vaild_encoder_pos.shape, \"\\n\", vaild_encoder_pos)\n",
    "# vaild_encoder_pos = torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(src_len)-L)),0) for L in src_len])\n",
    "print(vaild_encoder_pos.shape, \"\\n\", vaild_encoder_pos)\n",
    "# 这里不是三角矩阵\n",
    "# print(torch.tril(torch.ones(4, 4)))\n",
    "# vaild_mask = vaild_encoder_pos.transpose(1,2)*torch.ones(4, 4)*vaild_encoder_pos\n",
    "# print(vaild_mask.shape, \"\\n\", vaild_mask)\n",
    "# print(torch.bmm(torch.unsqueeze(torch.ones(4, 4),0), torch.unsqueeze(torch.ones(4, 4),0)))\n",
    "# print(torch.ones(4, 4)*torch.ones(4, 4))\n",
    "valid_encoder_pos_matrix = torch.bmm(vaild_encoder_pos, vaild_encoder_pos.transpose(1, 2))\n",
    "invalid_encoder_pos_matrix = 1-valid_encoder_pos_matrix\n",
    "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)\n",
    "print(mask_encoder_self_attention)\n",
    "#假设是vk注意力权重\n",
    "score = torch.randn(batch_size, max(src_len), max(src_len))\n",
    "masked_score = score.masked_fill(mask_encoder_self_attention, -np.inf)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5、get_attn_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 4]) \n",
      " torch.Size([2, 4, 1])\n",
      "tensor([[[1., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1.]]]) \n",
      " tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.]]])\n",
      "tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0.]]]) \n",
      " torch.Size([2, 4, 4])\n",
      "tensor([[[0.1897, 0.8103, 0.0000, 0.0000],\n",
      "         [0.3828, 0.6172, 0.0000, 0.0000],\n",
      "         [0.1205, 0.8795, 0.0000, 0.0000],\n",
      "         [0.7199, 0.2801, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2825, 0.4079, 0.1964, 0.1133],\n",
      "         [0.4752, 0.0532, 0.2524, 0.2193],\n",
      "         [0.1081, 0.4313, 0.3477, 0.1129],\n",
      "         [   nan,    nan,    nan,    nan]]])\n"
     ]
    }
   ],
   "source": [
    "enc_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(src_len)-L)),0) for L in src_len]), 1)\n",
    "dec_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(tgt_len)-L)),0) for L in tgt_len]), 2)\n",
    "print(enc_encoder_pos.shape, \"\\n\", dec_encoder_pos.shape)\n",
    "print(enc_encoder_pos, \"\\n\", dec_encoder_pos)\n",
    "# 具体维度通过【】的奇偶特征决定\n",
    "get_attn_pad_mask = torch.bmm(dec_encoder_pos, enc_encoder_pos, )\n",
    "print(get_attn_pad_mask, \"\\n\", get_attn_pad_mask.shape)\n",
    "score = torch.randn(2, max(src_len), max(tgt_len))\n",
    "masked_score = score.masked_fill((1-get_attn_pad_mask).to(torch.bool), -np.inf)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 6、dec_self_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 4])\n",
      "tensor([[[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "tensor([[[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "tril = torch.unsqueeze(torch.tril(torch.ones(max(tgt_len), max(tgt_len))), 0)\n",
    "print(tril.shape)\n",
    "# tril = tril.expand(2, 4, 4) \n",
    "tril = torch.cat((tril, tril ))\n",
    "print(tril)\n",
    "dec_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(tgt_len)-L)),0) for L in tgt_len]), 2)\n",
    "valid_decoder_pos_matrix = torch.bmm(dec_encoder_pos,dec_encoder_pos.transpose(1, 2))\n",
    "dec_self_attn_mask = valid_decoder_pos_matrix*tril\n",
    "print(dec_self_attn_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 7、loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.randn(2,3,4)\n",
    "# batchsize=2 seqlen=3 vocal_size=4\n",
    "label = torch.randint(0, 4, (2,3))\n",
    "logits = logits.transpose(1,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
