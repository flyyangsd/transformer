{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# print(\"当前设备名称：\", torch.cuda.get_device_name(device) if device.type == 'cuda' else 'CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1、生成词索引构成的序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 2, 0, 0, 0],\n",
      "        [2, 1, 1, 3, 0]])\n",
      "tensor([[7, 3, 4, 7, 0],\n",
      "        [6, 1, 2, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "model_dim = 8\n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "max_position_len = 5\n",
    "# src_len = torch.randint(2,5,(batch_size,))\n",
    "# tgt_len = torch.randint(2,5,(batch_size,))\n",
    "src_len = torch.Tensor([2, 4]).to(torch.int32)\n",
    "tgt_len = torch.Tensor([4, 3]).to(torch.int32)\n",
    "# 词索引构成的序列\n",
    "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_src_words, (L,)), (0, max_src_seq_len-L)), 0) \\\n",
    "                     for L in src_len])\n",
    "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_tgt_words, (L,)), (0, max_tgt_seq_len-L)), 0) \\\n",
    "                     for L in tgt_len])\n",
    "print(src_seq)\n",
    "print(tgt_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2、采用Embedding的forward方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9972, -1.1505, -0.3348, -0.7066,  0.9529, -0.6720, -1.0074,\n",
      "          -0.1062],\n",
      "         [ 1.6420, -0.5470,  0.7935, -0.8039,  0.8553,  0.5155,  0.7143,\n",
      "          -0.8774],\n",
      "         [ 1.4793, -0.1054, -0.5050, -0.5326, -0.2138,  0.4789,  0.4369,\n",
      "           0.5033],\n",
      "         [ 1.4793, -0.1054, -0.5050, -0.5326, -0.2138,  0.4789,  0.4369,\n",
      "           0.5033],\n",
      "         [ 1.4793, -0.1054, -0.5050, -0.5326, -0.2138,  0.4789,  0.4369,\n",
      "           0.5033]],\n",
      "\n",
      "        [[ 1.6420, -0.5470,  0.7935, -0.8039,  0.8553,  0.5155,  0.7143,\n",
      "          -0.8774],\n",
      "         [-1.9854, -1.8429,  1.2354,  0.1160, -1.1941,  1.4825,  1.6997,\n",
      "           0.3852],\n",
      "         [-1.9854, -1.8429,  1.2354,  0.1160, -1.1941,  1.4825,  1.6997,\n",
      "           0.3852],\n",
      "         [ 2.9460,  0.5091, -0.1044, -0.6461, -0.4602, -2.9577, -0.3628,\n",
      "           0.4591],\n",
      "         [ 1.4793, -0.1054, -0.5050, -0.5326, -0.2138,  0.4789,  0.4369,\n",
      "           0.5033]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 实例化embedding # requires_grad \n",
    "# weight是随机的，训练时更新\n",
    "src_embedding_table = nn.Embedding(max_num_src_words+1, model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1, model_dim)\n",
    "# print(src_embedding_table.weight, tgt_embedding_table.weight)\n",
    "# Embedding存在 --call-- forward方法隐式\n",
    "src_embedding = src_embedding_table(src_seq)\n",
    "tgt_embedding_table = tgt_embedding_table(tgt_seq)\n",
    "print(src_embedding)\n",
    "# 由于为0 底下3排一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3、生成pos—embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np Time (microseconds): 1000.6427764892578\n",
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  9.5042e-01,  9.9833e-02,  9.9950e-01,  9.9998e-03,\n",
      "          9.9999e-01,  1.0000e-03,  1.0000e+00],\n",
      "        [ 9.0930e-01,  8.0658e-01,  1.9867e-01,  9.9800e-01,  1.9999e-02,\n",
      "          9.9998e-01,  2.0000e-03,  1.0000e+00],\n",
      "        [ 1.4112e-01,  5.8275e-01,  2.9552e-01,  9.9550e-01,  2.9995e-02,\n",
      "          9.9995e-01,  3.0000e-03,  1.0000e+00],\n",
      "        [-7.5680e-01,  3.0114e-01,  3.8942e-01,  9.9201e-01,  3.9989e-02,\n",
      "          9.9992e-01,  4.0000e-03,  1.0000e+00]])\n",
      "torch Time (microseconds): 1004.9343109130859\n",
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# pos embedding    method1 \n",
    "start_time = time.time()\n",
    "pos_embedding = torch.zeros(max_position_len, model_dim)\n",
    "for i in range(0, model_dim):\n",
    "    for j in range(0, max_position_len):\n",
    "        if i%2 == 0:\n",
    "            # print(i,j)\n",
    "            pos_embedding[j, i] = np.sin(j/np.power(10000, (i/model_dim)))\n",
    "        else:\n",
    "            pos_embedding[j, i] = np.cos(j/np.power(10000, (i/model_dim)))\n",
    "# print(pos_embedding)\n",
    "end_time = time.time()\n",
    "# 计算执行时间并转换为微秒\n",
    "execution_time_microseconds = (end_time - start_time) * 1e6\n",
    "# 打印执行时间\n",
    "print(\"np Time (microseconds):\", execution_time_microseconds)\n",
    "#///////////////////////////////////////////////////////////////////////////////////////////\n",
    "# pos embedding    method2 \n",
    "start_time = time.time()\n",
    "pos_mat = torch.arange(max_position_len).reshape(-1, 1) \n",
    "i_mat = torch.pow(10000, torch.arange(0, 8, 2).reshape((1, -1))/model_dim)\n",
    "i1_mat = torch.pow(10000, torch.arange(1, 8, 2).reshape((1, -1))/model_dim)\n",
    "# print(pos_mat, i_mat, i1_mat)\n",
    "pe_embedding_table = torch.zeros(max_position_len, model_dim)\n",
    "pe_embedding_table[:, 0::2] = torch.sin(pos_mat/i_mat)\n",
    "pe_embedding_table[:, 1::2] = torch.cos(pos_mat/i1_mat)\n",
    "print(pe_embedding_table)\n",
    "end_time = time.time()\n",
    "# 计算执行时间并转换为微秒\n",
    "execution_time_microseconds = (end_time - start_time) * 1e6\n",
    "# 打印执行时间\n",
    "print(\"torch Time (microseconds):\", execution_time_microseconds)\n",
    "#///////////////////////////////////////////////////////////////////////////////////////////\n",
    "# print(torch.sub(pos_embedding, pe_embedding_table))\n",
    "pe_embedding = nn.Embedding(max_position_len, model_dim)\n",
    "# 位置编码训练中不发生变化requires_grad=False\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad=False)\n",
    "# 注意 这里给embedding的是位置 不是词的编号\n",
    "# src_p=torch.zeros_like(src_seq)\n",
    "# for i in range(src_p.size(0)):\n",
    "#     for j in range(src_p.size(1)):\n",
    "#         src_p[i][j] = j \n",
    "# print(src_p)\n",
    "# src_pe_embedding =pe_embedding(src_p)\n",
    "src_pe_embedding =pe_embedding(torch.cat([pos_mat,pos_mat], 1).transpose(-1,-2))\n",
    "print(torch.cat([pos_mat,pos_mat], 1).transpose(-1,-2))\n",
    "# print(src_pe_embedding)\n",
    "tgt_pe_embedding = src_pe_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 4、生成enc_self_attn_mask 无因果关系   对词向量相似度进行masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 1]) \n",
      " tensor([[[1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]])\n",
      "tensor([[[False, False,  True,  True],\n",
      "         [False, False,  True,  True],\n",
      "         [ True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False],\n",
      "         [False, False, False, False],\n",
      "         [False, False, False, False],\n",
      "         [False, False, False, False]]])\n",
      "tensor([[[0.6438, 0.3562, 0.0000, 0.0000],\n",
      "         [0.7154, 0.2846, 0.0000, 0.0000],\n",
      "         [   nan,    nan,    nan,    nan],\n",
      "         [   nan,    nan,    nan,    nan]],\n",
      "\n",
      "        [[0.0578, 0.7004, 0.1522, 0.0896],\n",
      "         [0.4073, 0.1918, 0.1333, 0.2676],\n",
      "         [0.2010, 0.1026, 0.1896, 0.5069],\n",
      "         [0.3123, 0.2943, 0.3177, 0.0758]]])\n"
     ]
    }
   ],
   "source": [
    "# 这里不是三角矩阵# 这里不是三角矩阵 没有因果关系 多用矩阵相乘 转置 升维\n",
    "vaild_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(src_len)-L)),0) for L in src_len]), 2)\n",
    "# print(vaild_encoder_pos.shape, \"\\n\", vaild_encoder_pos)\n",
    "# vaild_encoder_pos = torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(src_len)-L)),0) for L in src_len])\n",
    "print(vaild_encoder_pos.shape, \"\\n\", vaild_encoder_pos)\n",
    "# 这里不是三角矩阵\n",
    "# print(torch.tril(torch.ones(4, 4)))\n",
    "# vaild_mask = vaild_encoder_pos.transpose(1,2)*torch.ones(4, 4)*vaild_encoder_pos\n",
    "# print(vaild_mask.shape, \"\\n\", vaild_mask)\n",
    "# print(torch.bmm(torch.unsqueeze(torch.ones(4, 4),0), torch.unsqueeze(torch.ones(4, 4),0)))\n",
    "# print(torch.ones(4, 4)*torch.ones(4, 4))\n",
    "valid_encoder_pos_matrix = torch.bmm(vaild_encoder_pos, vaild_encoder_pos.transpose(1, 2))\n",
    "invalid_encoder_pos_matrix = 1-valid_encoder_pos_matrix\n",
    "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)\n",
    "print(mask_encoder_self_attention)\n",
    "#假设是vk注意力权重\n",
    "score = torch.randn(batch_size, max(src_len), max(src_len))\n",
    "masked_score = score.masked_fill(mask_encoder_self_attention, -np.inf)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5、get_attn_pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 4]) \n",
      " torch.Size([2, 4, 1])\n",
      "tensor([[[1., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1.]]]) \n",
      " tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.]]])\n",
      "tensor([[[1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0.]]]) \n",
      " torch.Size([2, 4, 4])\n",
      "tensor([[[0.6462, 0.3538, 0.0000, 0.0000],\n",
      "         [0.5447, 0.4553, 0.0000, 0.0000],\n",
      "         [0.7132, 0.2868, 0.0000, 0.0000],\n",
      "         [0.3079, 0.6921, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1295, 0.1881, 0.4646, 0.2179],\n",
      "         [0.0901, 0.0711, 0.2931, 0.5457],\n",
      "         [0.3193, 0.2181, 0.2850, 0.1776],\n",
      "         [   nan,    nan,    nan,    nan]]])\n"
     ]
    }
   ],
   "source": [
    "enc_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(src_len)-L)),0) for L in src_len]), 1)\n",
    "dec_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(tgt_len)-L)),0) for L in tgt_len]), 2)\n",
    "print(enc_encoder_pos.shape, \"\\n\", dec_encoder_pos.shape)\n",
    "print(enc_encoder_pos, \"\\n\", dec_encoder_pos)\n",
    "# 具体维度通过【】的奇偶特征决定\n",
    "get_attn_pad_mask = torch.bmm(dec_encoder_pos, enc_encoder_pos, )\n",
    "print(get_attn_pad_mask, \"\\n\", get_attn_pad_mask.shape)\n",
    "score = torch.randn(2, max(src_len), max(tgt_len))\n",
    "masked_score = score.masked_fill((1-get_attn_pad_mask).to(torch.bool), -np.inf)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 6、dec_self_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 4])\n",
      "tensor([[[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "tensor([[[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0.],\n",
      "         [1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "tril = torch.unsqueeze(torch.tril(torch.ones(max(tgt_len), max(tgt_len))), 0)\n",
    "print(tril.shape)\n",
    "# tril = tril.expand(2, 4, 4) \n",
    "tril = torch.cat((tril, tril ))\n",
    "print(tril)\n",
    "dec_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0, max(tgt_len)-L)),0) for L in tgt_len]), 2)\n",
    "valid_decoder_pos_matrix = torch.bmm(dec_encoder_pos,dec_encoder_pos.transpose(1, 2))\n",
    "dec_self_attn_mask = valid_decoder_pos_matrix*tril\n",
    "print(dec_self_attn_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 7、loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7906, 0.8456, 2.1394],\n",
      "        [1.2096, 1.2577, 1.1393]])\n",
      "tensor([[0.0000, 0.8456, 2.1394],\n",
      "        [1.2096, 1.2577, 1.1393]])\n",
      "tensor(1.5637)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.randn(2,3,4)\n",
    "# batchsize=2 seqlen=3 vocal_size=4\n",
    "label = torch.randint(0, 4, (2,3))\n",
    "logits = logits.transpose(1,2)\n",
    "print(F.cross_entropy(logits, label,reduction = 'none'))\n",
    "print(F.cross_entropy(logits, label,ignore_index = 2, reduction = 'none'))\n",
    "# print(F.cross_entropy(logits, label,ignore_index = 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESRGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
